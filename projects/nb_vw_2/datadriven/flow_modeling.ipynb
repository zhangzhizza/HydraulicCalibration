{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10949419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "#from changedetect.kuncheva2014 import get_change_value\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7caf5dcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2204408135.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    reg1_x_21 = p1_2021_nonzero[['NB2_S_1_NYZ_cwp_9_HzSPR_x', 'NB2_S_1_NYZ_cwp_10_HzSPR_x',\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# regression\n",
    "    # 2020 data\n",
    "    # prepare training and validataion data set\n",
    "    \n",
    "    # 2021 data\n",
    "    # prepare training and validataion data set\n",
    "    reg1_x_21 = p1_2021_nonzero[['NB2_S_1_NYZ_cwp_9_HzSPR_x', 'NB2_S_1_NYZ_cwp_10_HzSPR_x',\n",
    "                          'NB2_S_1_NYZ_cwp_11_HzSPR_x', 'NB2_S_1_NYZ_cwp_12_HzSPR_x',\n",
    "                          'p_diff']].values\n",
    "    reg1_y_21 = p1_2021_nonzero['NB2_S_x_NYZ_x_x_Fcw_x'].values\n",
    "    reg1_data_len_21 = len(reg1_x_21)\n",
    "    reg1_train_len_21 = int(reg1_data_len_21 * 0.6)\n",
    "    reg1_x_train_21 = reg1_x_21[0: reg1_train_len_21]\n",
    "    reg1_x_valid_21 = reg1_x_21[reg1_train_len_21: ]\n",
    "    reg1_y_train_21 = reg1_y_21[0: reg1_train_len_21]\n",
    "    reg1_y_valid_21 = reg1_y_21[reg1_train_len_21: ]\n",
    "    regr.fit(reg1_x_20, reg1_y_20) # the only line for training\n",
    "    print('Training R: %s'%regr.score(reg1_x_train_20, reg1_y_train_20))\n",
    "    ##############################################################################\n",
    "    # all the following codes are for plotting\n",
    "    \n",
    "    # 2020 validation data plot\n",
    "    reg1_y_pred_20 = regr.predict(reg1_x_valid_20)\n",
    "    fig, ax=plt.subplots(figsize = (20, 10))\n",
    "    ax.plot(reg1_y_valid_20, color = 'blue', label = 'true')\n",
    "    ax.plot(reg1_y_pred_20, color = 'green', label = 'pred')\n",
    "    for x_i in range(0, len(reg1_y_pred_20), one_day_n):\n",
    "        ax.axvline(x=x_i, ymin=0, ymax=300)\n",
    "        ax.text(x=x_i, y=300, s='%s'%(x_i/one_day_n), fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.set_title('Validation using 2020 data')\n",
    "    fig.show()\n",
    "    print('Validation R: %s'%regr.score(reg1_x_valid_20, reg1_y_valid_20))\n",
    "    # 2020 validation data daily distribution change vs prediction error\n",
    "    day_range = 1 ################\n",
    "    daily_errors = []\n",
    "    daily_dist_changes = []\n",
    "    for day_i in range(0, int(len(reg1_y_valid_20)/one_day_n), day_range):\n",
    "        new_data = reg1_x_valid_20[day_i * one_day_n: (day_i + day_range) * one_day_n]\n",
    "        new_data_pred_y = regr.predict(new_data)\n",
    "        new_data_true_y = reg1_y_valid_20[day_i * one_day_n: (day_i + day_range) * one_day_n]\n",
    "        new_data_r2 = regr.score(new_data, new_data_true_y)#np.mean(np.abs(new_data_pred_y - new_data_true_y)/new_data_true_y)\n",
    "        daily_errors.append(new_data_r2)\n",
    "        change_val = get_change_value(org_data=reg1_x_train_20, new_data=new_data, \n",
    "                                     pca_exp_thres=0.25, cluster_n=3)\n",
    "        daily_dist_changes.append(change_val)\n",
    "    fig, ax=plt.subplots(figsize = (5, 5))\n",
    "    ax.scatter(daily_dist_changes, daily_errors)\n",
    "    ax.set_title('2020 validation data R2 vs. distribution change')\n",
    "    fig.show()\n",
    "    # print r2 and distribution change\n",
    "    r2dist_df = pd.DataFrame(np.array([daily_dist_changes, daily_errors]).T)\n",
    "    r2dist_df.columns = ['dist change', 'r2']\n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "    print(r2dist_df)\n",
    "    # 2021 test data plot\n",
    "    reg1_y_pred_21 = regr.predict(reg1_x_21)\n",
    "    fig, ax=plt.subplots(figsize = (20, 5))\n",
    "    ax.plot(reg1_y_21, color = 'blue', label = 'true')\n",
    "    ax.plot(reg1_y_pred_21, color = 'green', label = 'pred')\n",
    "    for x_i in range(0, len(reg1_y_21), one_day_n):\n",
    "        ax.axvline(x=x_i, ymin=0, ymax=300)\n",
    "        ax.text(x=x_i, y=300, s='%s'%(x_i/one_day_n), fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.set_title('Test using 2021 data')\n",
    "    fig.show()\n",
    "    print('Test in 2021 R: %s'%regr.score(reg1_x_21, reg1_y_21))\n",
    "    # distribution change\n",
    "    print('Distribution difference between 2020 training and validation dataset is: %s'%get_change_value(org_data=reg1_x_train_20, new_data=reg1_x_valid_20, \n",
    "                 pca_exp_thres=0.25, cluster_n=3))\n",
    "    print('Distribution difference between 2020 and 2021 dataset is: %s'%get_change_value(org_data=reg1_x_20, new_data=reg1_x_21, \n",
    "                 pca_exp_thres=0.25, cluster_n=3))\n",
    "    daily_dist_changes = []\n",
    "    daily_errors = []\n",
    "    print(reg1_data_len_21)\n",
    "    print(one_day_n)\n",
    "    for day_i in range(0, int(reg1_data_len_21/one_day_n), day_range):\n",
    "        new_data = reg1_x_21[day_i * one_day_n: (day_i + day_range) * one_day_n]\n",
    "        new_data_pred_y = regr.predict(new_data)\n",
    "        new_data_true_y = reg1_y_21[day_i * one_day_n: (day_i + day_range) * one_day_n]\n",
    "        new_data_r2 = regr.score(new_data, new_data_true_y)#np.mean(np.abs(new_data_pred_y - new_data_true_y)/new_data_true_y)\n",
    "        daily_errors.append(new_data_r2)\n",
    "        change_val = get_change_value(org_data=reg1_x_train_20, new_data=new_data, \n",
    "                                     pca_exp_thres=0.25, cluster_n=3)\n",
    "        daily_dist_changes.append(change_val)\n",
    "    fig, ax=plt.subplots(figsize = (5, 5))\n",
    "    ax.scatter(daily_dist_changes, daily_errors)\n",
    "    ax.set_title('R2 vs. distribution change')\n",
    "    fig.show()\n",
    "    # print r2 and distribution change\n",
    "    r2dist_df = pd.DataFrame(np.array([daily_dist_changes, daily_errors]).T)\n",
    "    r2dist_df.columns = ['dist change', 'r2']\n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "    print(r2dist_df)\n",
    "    # perform error analysis using multivariate distribution\n",
    "    reg1_x_20_mean = np.mean(reg1_x_20, axis = 0)\n",
    "    reg1_x_20_cov = np.cov(reg1_x_20, rowvar = False)\n",
    "    reg1_x_dist = sp.stats.multivariate_normal(mean = reg1_x_20_mean, \n",
    "                                         cov = reg1_x_20_cov)\n",
    "    valid20_dist2mean = []\n",
    "    for train_pt in reg1_x_valid_20:\n",
    "        test_dist2mean = np.matmul(np.matmul((train_pt - reg1_x_20_mean),\n",
    "                                     np.linalg.inv(reg1_x_20_cov)),\n",
    "                           (train_pt - reg1_x_20_mean).T)\n",
    "        valid20_dist2mean.append(test_dist2mean)\n",
    "    fig, ax=plt.subplots(figsize = (20, 5))\n",
    "    ax.plot(reg1_y_valid_20, color = 'blue', label = 'true')\n",
    "    ax.plot(reg1_y_pred_20, color = 'green', label = 'pred')\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(valid20_dist2mean, color = 'red', label = 'dist2mean')\n",
    "    ax.legend()\n",
    "    ax2.legend()\n",
    "    ax.set_title('Validation using 2020 data')\n",
    "    fig.show()\n",
    "    test21_dist2mean = []\n",
    "    test21_mapes = np.abs(reg1_y_pred_21 - reg1_y_21)/reg1_y_21\n",
    "    for train_pt in reg1_x_21:\n",
    "        test_dist2mean = np.matmul(np.matmul((train_pt - reg1_x_20_mean),\n",
    "                                     np.linalg.inv(reg1_x_20_cov)),\n",
    "                           (train_pt - reg1_x_20_mean).T)\n",
    "        test21_dist2mean.append(test_dist2mean)\n",
    "    fig, ax=plt.subplots(figsize = (20, 5))\n",
    "    ax.plot(reg1_y_21, color = 'blue', label = 'true')\n",
    "    ax.plot(reg1_y_pred_21, color = 'green', label = 'pred')\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(test21_dist2mean, color = 'red', label = 'dist2mean')\n",
    "    ax.legend()\n",
    "    ax.set_title('Test using 2021 data')\n",
    "    fig.show()\n",
    "    \n",
    "    x20_dist2mean = []\n",
    "    for train_pt in reg1_x_20:\n",
    "        test_dist2mean = np.matmul(np.matmul((train_pt - reg1_x_20_mean),\n",
    "                                     np.linalg.inv(reg1_x_20_cov)),\n",
    "                           (train_pt - reg1_x_20_mean).T)\n",
    "        x20_dist2mean.append(test_dist2mean)\n",
    "        \n",
    "    fig, ax=plt.subplots(figsize = (5, 5))\n",
    "    ax.scatter(test21_dist2mean, test21_mapes)\n",
    "    ax.set_title('dist2mean vs. mape')\n",
    "    fig.show()\n",
    "    # dist2mean cmp\n",
    "    fig, ax=plt.subplots(figsize = (20, 5))\n",
    "    ax.plot(x20_dist2mean, color = 'blue', label = '2020 dist2mean')\n",
    "    ax.plot(test21_dist2mean, color = 'green', label = '2021 dist2mean')\n",
    "    ax.legend()\n",
    "    ax.set_title('2020 vs 2021 dist2mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0781a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(groupby_n):\n",
    "    one_day_n = int(24*(60/groupby_n))\n",
    "    ######################## Year 2020 data #######################\n",
    "    # read flow data\n",
    "    p1_2020 = pd.read_csv('./raw_data/EndUserData2020P2.csv')\n",
    "    # perform time integration on data\n",
    "    p1_2020 = p1_2020.groupby(p1_2020.index // groupby_n).mean()\n",
    "    # select data with flow larger than 500 (ignore small flow data)\n",
    "    p1_2020_nonzero = p1_2020.loc[p1_2020['NB2_S_x_NYZ_x_x_Fcw_x']>500]\n",
    "    # read on/off state data\n",
    "    p1_2020_state = pd.read_csv('./raw_data/EndUserData2020P2CWPState.csv')\n",
    "    # perform time integration on data\n",
    "    p1_2020_state = p1_2020_state.groupby(p1_2020_state.index // groupby_n).mean()\n",
    "    # select data with flow larger than 500 (ignore small flow data)\n",
    "    p1_2020_state_nonzero = p1_2020_state.loc[p1_2020['NB2_S_x_NYZ_x_x_Fcw_x']>500]\n",
    "    # if the pump is off, set the frequency to zero\n",
    "    p1_2020_nonzero['NB2_S_1_NYZ_cwp_9_HzSPR_x'] = p1_2020_nonzero['NB2_S_1_NYZ_cwp_9_HzSPR_x']\\\n",
    "                                            * p1_2020_state_nonzero['NB2_S_1_NYZ_cwp_9_State_x']\n",
    "    p1_2020_nonzero['NB2_S_1_NYZ_cwp_10_HzSPR_x'] = p1_2020_nonzero['NB2_S_1_NYZ_cwp_10_HzSPR_x']\\\n",
    "                                            * p1_2020_state_nonzero['NB2_S_1_NYZ_cwp_10_State_x']\n",
    "    p1_2020_nonzero['NB2_S_1_NYZ_cwp_11_HzSPR_x'] = p1_2020_nonzero['NB2_S_1_NYZ_cwp_11_HzSPR_x']\\\n",
    "                                            * p1_2020_state_nonzero['NB2_S_1_NYZ_cwp_11_State_x']\n",
    "    p1_2020_nonzero['NB2_S_1_NYZ_cwp_12_HzSPR_x'] = p1_2020_nonzero['NB2_S_1_NYZ_cwp_12_HzSPR_x']\\\n",
    "                                            * p1_2020_state_nonzero['NB2_S_1_NYZ_cwp_12_State_x']\n",
    "    # get pressure difference\n",
    "    p1_2020_nonzero['p_diff'] =  p1_2020_nonzero['NB2_S_1_NYZ_sys_x_PcwOut_x'] - p1_2020_nonzero['NB2_S_1_NYZ_sys_x_PcwIn_x']\n",
    "    ######################## Year 2021 data ##########################\n",
    "    # same procedure apply to 2021 data\n",
    "    p1_2021 = pd.read_csv('./raw_data/EndUserData2021P2_fix.csv')\n",
    "    p1_2021_isnan = p1_2021.isnull().sum(axis = 1).values.flatten()\n",
    "    p1_2021_nonidx = np.argwhere(p1_2021_isnan > 0).flatten()\n",
    "    #p1_2021_nonidx = np.where(pd.isnull(p1_2021).any(1) == 1)[0]\n",
    "    p1_2021 = p1_2021.drop(p1_2021_nonidx)\n",
    "    p1_2021 = p1_2021.groupby(p1_2021.index // groupby_n).mean()\n",
    "    p1_2021_nonzero = p1_2021.loc[p1_2021['NB2_S_x_NYZ_x_x_Fcw_x']>500]\n",
    "    \n",
    "    p1_2021_state = pd.read_csv('./raw_data/EndUserData2021P2CWPState.csv')\n",
    "    p1_2021_state = p1_2021_state.drop(p1_2021_nonidx)\n",
    "    p1_2021_state = p1_2021_state.groupby(p1_2021_state.index // groupby_n).mean()\n",
    "    p1_2021_state_nonzero = p1_2021_state.loc[p1_2021['NB2_S_x_NYZ_x_x_Fcw_x']>500]\n",
    "    \n",
    "    \n",
    "    p1_2021_nonzero['NB2_S_1_NYZ_cwp_9_HzSPR_x'] = p1_2021_nonzero['NB2_S_1_NYZ_cwp_9_HzSPR_x']\\\n",
    "                                            * p1_2021_state_nonzero['NB2_S_1_NYZ_cwp_9_State_x']\n",
    "    p1_2021_nonzero['NB2_S_1_NYZ_cwp_10_HzSPR_x'] = p1_2021_nonzero['NB2_S_1_NYZ_cwp_10_HzSPR_x']\\\n",
    "                                            * p1_2021_state_nonzero['NB2_S_1_NYZ_cwp_10_State_x']\n",
    "    p1_2021_nonzero['NB2_S_1_NYZ_cwp_11_HzSPR_x'] = p1_2021_nonzero['NB2_S_1_NYZ_cwp_11_HzSPR_x']\\\n",
    "                                            * p1_2021_state_nonzero['NB2_S_1_NYZ_cwp_11_State_x']\n",
    "    p1_2021_nonzero['NB2_S_1_NYZ_cwp_12_HzSPR_x'] = p1_2021_nonzero['NB2_S_1_NYZ_cwp_12_HzSPR_x']\\\n",
    "                                            * p1_2021_state_nonzero['NB2_S_1_NYZ_cwp_12_State_x']\n",
    "    p1_2021_nonzero['p_diff'] =  p1_2021_nonzero['NB2_S_1_NYZ_sys_x_PcwOut_x'] - p1_2021_nonzero['NB2_S_1_NYZ_sys_x_PcwIn_x']\n",
    "    ###################################################################################################################\n",
    "    return p1_2020_nonzero, p1_2021_nonzero\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fae5989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def get_best_model(estimator: BaseEstimator,\n",
    "                   train_x: np.ndarray,\n",
    "                   train_y: np.ndarray,\n",
    "                   parameters_grid: dict,\n",
    "                   cv_n: int):\n",
    "    clf = GridSearchCV(estimator = estimator, \n",
    "                       param_grid = parameters_grid, \n",
    "                       cv = cv_n, \n",
    "                       scoring = 'neg_mean_absolute_error',\n",
    "                       verbose = 1)\n",
    "    clf.fit(train_x, train_y)\n",
    "    best_estimator = clf.best_estimator_\n",
    "    grid_res = clf.cv_results_\n",
    "    return best_estimator, grid_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6dbf0bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "############### Read the raw data #############\n",
    "groupby_n = 60\n",
    "datadriven_res_dir = \"datadriven_res\"\n",
    "if not os.path.isdir(datadriven_res_dir):\n",
    "    os.mkdir(datadriven_res_dir)\n",
    "p1_20_df, p1_21_df = data_preprocess(groupby_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "60b13070",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_20_df_tosave, p1_21_df_tosave = data_preprocess(groupby_n)\n",
    "\n",
    "p1_21_df_tosave['NB2_S_1_NYZ_sys_x_PcwOut_x'] *= 100000\n",
    "p1_21_df_tosave['NB2_S_1_NYZ_sys_x_PcwIn_x'] *= 100000\n",
    "p1_21_df_tosave['NB2_S_x_NYZ_x_x_Fcw_x'] /= 3.6\n",
    "p1_21_df_tosave['cwp_9_val_pos'] = (p1_21_df_tosave['NB2_S_1_NYZ_cwp_9_HzSPR_x'] > 0) + (p1_21_df_tosave['NB2_S_1_NYZ_cwp_9_HzSPR_x'] == 0)*0.001\n",
    "p1_21_df_tosave['cwp_10_val_pos'] = (p1_21_df_tosave['NB2_S_1_NYZ_cwp_10_HzSPR_x'] > 0) + (p1_21_df_tosave['NB2_S_1_NYZ_cwp_10_HzSPR_x'] == 0)*0.001\n",
    "p1_21_df_tosave['cwp_11_val_pos'] = (p1_21_df_tosave['NB2_S_1_NYZ_cwp_11_HzSPR_x'] > 0) + (p1_21_df_tosave['NB2_S_1_NYZ_cwp_11_HzSPR_x'] == 0)*0.001\n",
    "p1_21_df_tosave['cwp_12_val_pos'] = (p1_21_df_tosave['NB2_S_1_NYZ_cwp_12_HzSPR_x'] > 0) + (p1_21_df_tosave['NB2_S_1_NYZ_cwp_12_HzSPR_x'] == 0)*0.001\n",
    "p1_21_df_tosave = p1_21_df_tosave[['NB2_S_1_NYZ_sys_x_PcwOut_x', 'NB2_S_1_NYZ_sys_x_PcwIn_x',\n",
    "                                  'NB2_S_1_NYZ_cwp_9_HzSPR_x', 'NB2_S_1_NYZ_cwp_10_HzSPR_x',\n",
    "                                  'NB2_S_1_NYZ_cwp_11_HzSPR_x', 'NB2_S_1_NYZ_cwp_12_HzSPR_x',\n",
    "                                  'NB2_S_x_NYZ_x_x_Fcw_x', 'cwp_9_val_pos', 'cwp_10_val_pos',\n",
    "                                  'cwp_11_val_pos', 'cwp_12_val_pos', 'ts']]\n",
    "p1_21_df_tosave.to_csv('../2021P2_calibration_data_60m.csv')\n",
    "\n",
    "p1_20_df_tosave['NB2_S_1_NYZ_sys_x_PcwOut_x'] *= 100000\n",
    "p1_20_df_tosave['NB2_S_1_NYZ_sys_x_PcwIn_x'] *= 100000\n",
    "p1_20_df_tosave['NB2_S_x_NYZ_x_x_Fcw_x'] /= 3.6\n",
    "p1_20_df_tosave['cwp_9_val_pos'] = (p1_20_df_tosave['NB2_S_1_NYZ_cwp_9_HzSPR_x'] > 0) + (p1_20_df_tosave['NB2_S_1_NYZ_cwp_9_HzSPR_x'] == 0)*0.001\n",
    "p1_20_df_tosave['cwp_10_val_pos'] = (p1_20_df_tosave['NB2_S_1_NYZ_cwp_10_HzSPR_x'] > 0) + (p1_20_df_tosave['NB2_S_1_NYZ_cwp_10_HzSPR_x'] == 0)*0.001\n",
    "p1_20_df_tosave['cwp_11_val_pos'] = (p1_20_df_tosave['NB2_S_1_NYZ_cwp_11_HzSPR_x'] > 0) + (p1_20_df_tosave['NB2_S_1_NYZ_cwp_11_HzSPR_x'] == 0)*0.001\n",
    "p1_20_df_tosave['cwp_12_val_pos'] = (p1_20_df_tosave['NB2_S_1_NYZ_cwp_12_HzSPR_x'] > 0) + (p1_20_df_tosave['NB2_S_1_NYZ_cwp_12_HzSPR_x'] == 0)*0.001\n",
    "p1_20_df_tosave = p1_20_df_tosave[['NB2_S_1_NYZ_sys_x_PcwOut_x', 'NB2_S_1_NYZ_sys_x_PcwIn_x',\n",
    "                                  'NB2_S_1_NYZ_cwp_9_HzSPR_x', 'NB2_S_1_NYZ_cwp_10_HzSPR_x',\n",
    "                                  'NB2_S_1_NYZ_cwp_11_HzSPR_x', 'NB2_S_1_NYZ_cwp_12_HzSPR_x',\n",
    "                                  'NB2_S_x_NYZ_x_x_Fcw_x', 'cwp_9_val_pos', 'cwp_10_val_pos',\n",
    "                                  'cwp_11_val_pos', 'cwp_12_val_pos', 'ts']]\n",
    "p1_20_df_tosave.to_csv('../2020P2_calibration_data_60m.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bd408cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB2_S_1_NYZ_sys_x_PcwOut_x</th>\n",
       "      <th>NB2_S_1_NYZ_sys_x_PcwIn_x</th>\n",
       "      <th>NB2_S_1_NYZ_cwp_9_HzSPR_x</th>\n",
       "      <th>NB2_S_1_NYZ_cwp_10_HzSPR_x</th>\n",
       "      <th>NB2_S_1_NYZ_cwp_11_HzSPR_x</th>\n",
       "      <th>NB2_S_1_NYZ_cwp_12_HzSPR_x</th>\n",
       "      <th>NB2_S_x_NYZ_x_x_Fcw_x</th>\n",
       "      <th>cwp_9_val_pos</th>\n",
       "      <th>cwp_10_val_pos</th>\n",
       "      <th>cwp_11_val_pos</th>\n",
       "      <th>cwp_12_val_pos</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443600.000000</td>\n",
       "      <td>383622.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.747735</td>\n",
       "      <td>26.747735</td>\n",
       "      <td>564.294074</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1593534570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449850.000000</td>\n",
       "      <td>389973.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.974013</td>\n",
       "      <td>26.974013</td>\n",
       "      <td>570.878148</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1593538170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448033.333333</td>\n",
       "      <td>387862.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.914670</td>\n",
       "      <td>26.914670</td>\n",
       "      <td>566.873333</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1593541770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>450833.333333</td>\n",
       "      <td>391000.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.573610</td>\n",
       "      <td>26.573610</td>\n",
       "      <td>557.906713</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1593545370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>471800.000000</td>\n",
       "      <td>411892.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.561350</td>\n",
       "      <td>26.561350</td>\n",
       "      <td>558.878519</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1593548970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>512916.666667</td>\n",
       "      <td>418387.833333</td>\n",
       "      <td>29.173945</td>\n",
       "      <td>29.173832</td>\n",
       "      <td>29.180012</td>\n",
       "      <td>6.351972</td>\n",
       "      <td>898.685556</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1598876970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>522716.666667</td>\n",
       "      <td>438598.500000</td>\n",
       "      <td>28.705215</td>\n",
       "      <td>28.703798</td>\n",
       "      <td>28.704673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>839.655139</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1598880570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>523216.666667</td>\n",
       "      <td>439943.833333</td>\n",
       "      <td>28.672088</td>\n",
       "      <td>28.698398</td>\n",
       "      <td>28.698303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>836.551481</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1598884170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>519483.333333</td>\n",
       "      <td>435242.833333</td>\n",
       "      <td>28.817302</td>\n",
       "      <td>28.807480</td>\n",
       "      <td>28.802953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>843.484167</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1598887770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>516000.000000</td>\n",
       "      <td>429690.000000</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>28.882500</td>\n",
       "      <td>28.882500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>847.344444</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1598889600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1315 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NB2_S_1_NYZ_sys_x_PcwOut_x  NB2_S_1_NYZ_sys_x_PcwIn_x  \\\n",
       "0                  443600.000000              383622.000000   \n",
       "1                  449850.000000              389973.833333   \n",
       "2                  448033.333333              387862.500000   \n",
       "3                  450833.333333              391000.333333   \n",
       "4                  471800.000000              411892.833333   \n",
       "...                          ...                        ...   \n",
       "1484               512916.666667              418387.833333   \n",
       "1485               522716.666667              438598.500000   \n",
       "1486               523216.666667              439943.833333   \n",
       "1487               519483.333333              435242.833333   \n",
       "1488               516000.000000              429690.000000   \n",
       "\n",
       "      NB2_S_1_NYZ_cwp_9_HzSPR_x  NB2_S_1_NYZ_cwp_10_HzSPR_x  \\\n",
       "0                      0.000000                    0.000000   \n",
       "1                      0.000000                    0.000000   \n",
       "2                      0.000000                    0.000000   \n",
       "3                      0.000000                    0.000000   \n",
       "4                      0.000000                    0.000000   \n",
       "...                         ...                         ...   \n",
       "1484                  29.173945                   29.173832   \n",
       "1485                  28.705215                   28.703798   \n",
       "1486                  28.672088                   28.698398   \n",
       "1487                  28.817302                   28.807480   \n",
       "1488                  28.900000                   28.882500   \n",
       "\n",
       "      NB2_S_1_NYZ_cwp_11_HzSPR_x  NB2_S_1_NYZ_cwp_12_HzSPR_x  \\\n",
       "0                      26.747735                   26.747735   \n",
       "1                      26.974013                   26.974013   \n",
       "2                      26.914670                   26.914670   \n",
       "3                      26.573610                   26.573610   \n",
       "4                      26.561350                   26.561350   \n",
       "...                          ...                         ...   \n",
       "1484                   29.180012                    6.351972   \n",
       "1485                   28.704673                    0.000000   \n",
       "1486                   28.698303                    0.000000   \n",
       "1487                   28.802953                    0.000000   \n",
       "1488                   28.882500                    0.000000   \n",
       "\n",
       "      NB2_S_x_NYZ_x_x_Fcw_x  cwp_9_val_pos  cwp_10_val_pos  cwp_11_val_pos  \\\n",
       "0                564.294074          0.001           0.001             1.0   \n",
       "1                570.878148          0.001           0.001             1.0   \n",
       "2                566.873333          0.001           0.001             1.0   \n",
       "3                557.906713          0.001           0.001             1.0   \n",
       "4                558.878519          0.001           0.001             1.0   \n",
       "...                     ...            ...             ...             ...   \n",
       "1484             898.685556          1.000           1.000             1.0   \n",
       "1485             839.655139          1.000           1.000             1.0   \n",
       "1486             836.551481          1.000           1.000             1.0   \n",
       "1487             843.484167          1.000           1.000             1.0   \n",
       "1488             847.344444          1.000           1.000             1.0   \n",
       "\n",
       "      cwp_12_val_pos          ts  \n",
       "0              1.000  1593534570  \n",
       "1              1.000  1593538170  \n",
       "2              1.000  1593541770  \n",
       "3              1.000  1593545370  \n",
       "4              1.000  1593548970  \n",
       "...              ...         ...  \n",
       "1484           1.000  1598876970  \n",
       "1485           0.001  1598880570  \n",
       "1486           0.001  1598884170  \n",
       "1487           0.001  1598887770  \n",
       "1488           0.001  1598889600  \n",
       "\n",
       "[1315 rows x 12 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_20_df_tosave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b54849b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 169 candidates, totalling 845 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############### Do grid serach for hyperparameter tuning ################\n",
    "# prepare different regressors\n",
    "estimators_dict = {}\n",
    "\n",
    "mlp_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('mlp', MLPRegressor(hidden_layer_sizes=(100,), max_iter=2000, \n",
    "                            random_state=1, learning_rate = 'adaptive'))])\n",
    "mlp_parameters_grid = dict(mlp__hidden_layer_sizes=[(16, ), (32, ), (64, ), (128, ), (256,), \n",
    "                                                    (16, 16), (32, 32), (64, 64), (128, 128), (256, 256), \n",
    "                                                    (16, 16, 16), (32, 32, 32), (64, 64, 64), (128, 128, 128), (256, 256, 256)])\n",
    "estimators_dict['mlp'] = {'estimator': mlp_pipe, 'parameters_grid': mlp_parameters_grid}\n",
    "\n",
    "xgb_pipe = Pipeline([('scaler', StandardScaler()), ('xgb', xgb.XGBRegressor())])\n",
    "xgb_parameters_grid = dict(xgb__max_depth = [2, 4, 6, 8, 10, 12, 14, 16],\n",
    "                           xgb__n_estimators = [16, 32, 64, 128, 256, 512])\n",
    "estimators_dict['xgb'] = {'estimator': xgb_pipe, 'parameters_grid': xgb_parameters_grid}\n",
    "\n",
    "poly_pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('ridge', Ridge())])\n",
    "poly_parameters_grid = dict(poly__degree = [2, 3, 4, 5],\n",
    "                           ridge__alpha = [0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "estimators_dict['poly'] = {'estimator': poly_pipe, 'parameters_grid': poly_parameters_grid}\n",
    "svr_pipe = Pipeline([('scaler', StandardScaler()), ('svr', SVR())])\n",
    "svr_parameters_grid = dict(svr__gamma = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "                           svr__C = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100])\n",
    "estimators_dict['svr'] = {'estimator': svr_pipe, 'parameters_grid': svr_parameters_grid}\n",
    "# do grid search\n",
    "train_x = p1_20_df[['NB2_S_1_NYZ_cwp_9_HzSPR_x', 'NB2_S_1_NYZ_cwp_10_HzSPR_x',\n",
    "                          'NB2_S_1_NYZ_cwp_11_HzSPR_x', 'NB2_S_1_NYZ_cwp_12_HzSPR_x',\n",
    "                          'p_diff']].values\n",
    "train_y = p1_20_df['NB2_S_x_NYZ_x_x_Fcw_x'].values\n",
    "test_x = p1_21_df[['NB2_S_1_NYZ_cwp_9_HzSPR_x', 'NB2_S_1_NYZ_cwp_10_HzSPR_x',\n",
    "                          'NB2_S_1_NYZ_cwp_11_HzSPR_x', 'NB2_S_1_NYZ_cwp_12_HzSPR_x',\n",
    "                          'p_diff']].values\n",
    "test_y = p1_21_df['NB2_S_x_NYZ_x_x_Fcw_x'].values\n",
    "\n",
    "for estimator_key, estimator_val in estimators_dict.items():\n",
    "    estimator_i = estimator_val['estimator']\n",
    "    parameters_grid_i = estimator_val['parameters_grid']\n",
    "    best_model_i, grid_res_i = get_best_model(estimator = estimator_i,\n",
    "                       train_x = train_x,\n",
    "                       train_y = train_y,\n",
    "                       parameters_grid = parameters_grid_i,\n",
    "                       cv_n = 5)\n",
    "    train_ypred = best_model_i.predict(train_x)\n",
    "    test_ypred = best_model_i.predict(test_x)\n",
    "    train_res_df = pd.DataFrame(np.array([train_ypred, train_y]).T, columns = ['Fcw_ypred', 'Fcw_yobse'])\n",
    "    train_res_df['ts'] = p1_20_df['ts']\n",
    "    test_res_df = pd.DataFrame(np.array([test_ypred, test_y]).T, columns = ['Fcw_ypred', 'Fcw_yobse'])\n",
    "    test_res_df['ts'] = p1_21_df['ts']\n",
    "    test_ts_res_path_i = f'{datadriven_res_dir}/{estimator_key}_test_ts_res.csv'\n",
    "    test_res_df.to_csv(test_ts_res_path_i)\n",
    "    train_ts_res_path_i = f'{datadriven_res_dir}/{estimator_key}_train_ts_res.csv'\n",
    "    train_res_df.to_csv(train_ts_res_path_i)\n",
    "    grid_res_path_i = f'{datadriven_res_dir}/{estimator_key}_grid_search_res.pkl'\n",
    "    with open(grid_res_path_i, \"wb\") as file:\n",
    "        pickle.dump(grid_res_i, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b75aaba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(test_x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bcb26ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=10, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a207d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b6a389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b617078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
